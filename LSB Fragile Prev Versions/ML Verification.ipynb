{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdaba92c-f278-4a76-8d52-9f0d91efcaae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report, roc_curve, auc\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸ“˜ MACHINE LEARNING ENHANCEMENT FOR WATERMARK VERIFICATION\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2, json, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import seaborn as sns\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ Minimal Watermarking Core (simplified for ML pipeline)\n",
    "# ============================================================\n",
    "\n",
    "class SimpleWatermarkSystem:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess_image(self, image_bytesio):\n",
    "        image = Image.open(image_bytesio).convert('L')\n",
    "        image = np.array(image.resize((128, 128))).astype(np.float32) / 255.0\n",
    "        return image\n",
    "\n",
    "    def calculate_complexity(self, image):\n",
    "        gx, gy = np.gradient(image)\n",
    "        return np.mean(np.sqrt(gx**2 + gy**2))\n",
    "\n",
    "    def adaptive_alpha(self, complexity):\n",
    "        return 0.05 + 0.3 * complexity\n",
    "\n",
    "    def text_to_watermark(self, text, size=(32, 32)):\n",
    "        bits = np.frombuffer(text.encode('utf-8'), dtype=np.uint8)\n",
    "        bits = np.unpackbits(bits)[:size[0]*size[1]]\n",
    "        return bits.reshape(size).astype(np.float32)\n",
    "\n",
    "    def embed_watermark(self, host, watermark, alpha):\n",
    "        host_f = cv2.dct(host)\n",
    "        wm_resized = cv2.resize(watermark, host_f.shape)\n",
    "        watermarked_f = host_f + alpha * wm_resized\n",
    "        watermarked = cv2.idct(watermarked_f)\n",
    "        return np.clip(watermarked, 0, 1)\n",
    "\n",
    "    def extract_features(self, original, tampered):\n",
    "        complexity = self.calculate_complexity(original)\n",
    "        alpha = self.adaptive_alpha(complexity)\n",
    "        ssim_val = ssim(original, tampered)\n",
    "        mse = np.mean((original - tampered)**2)\n",
    "        psnr = 10 * np.log10(1.0 / (mse + 1e-12))\n",
    "        corr = np.corrcoef(original.flatten(), tampered.flatten())[0,1]\n",
    "        hist_o, _ = np.histogram(original, bins=32, range=(0,1), density=True)\n",
    "        hist_t, _ = np.histogram(tampered, bins=32, range=(0,1), density=True)\n",
    "        hist_dist = np.sum(np.abs(hist_o - hist_t))\n",
    "        return np.array([complexity, alpha, ssim_val, mse, psnr, corr, hist_dist], dtype=np.float32)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§ª Dataset Generation (synthetic images)\n",
    "# ============================================================\n",
    "\n",
    "def generate_synthetic_image(size=128):\n",
    "    \"\"\"Generate simple grayscale patterns.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.float32)\n",
    "    shape_type = random.choice(['circle','square','gradient'])\n",
    "    if shape_type == 'circle':\n",
    "        cv2.circle(img, (64,64), 30, random.uniform(0.4,0.9), -1)\n",
    "    elif shape_type == 'square':\n",
    "        cv2.rectangle(img, (32,32), (96,96), random.uniform(0.4,0.9), -1)\n",
    "    else:\n",
    "        img = np.tile(np.linspace(0,1,size), (size,1))\n",
    "    return img\n",
    "\n",
    "def apply_random_tamper(image):\n",
    "    tampered = image.copy()\n",
    "    tamper_type = random.choice(['noise','blur','crop','bright','contrast'])\n",
    "    if tamper_type == 'noise':\n",
    "        tampered += np.random.normal(0,0.05,tampered.shape)\n",
    "    elif tamper_type == 'blur':\n",
    "        tampered = cv2.GaussianBlur(tampered, (5,5), 1.0)\n",
    "    elif tamper_type == 'crop':\n",
    "        tampered[40:60,40:60] = 0.5\n",
    "    elif tamper_type == 'bright':\n",
    "        tampered = np.clip(tampered*1.2,0,1)\n",
    "    elif tamper_type == 'contrast':\n",
    "        tampered = np.clip((tampered-0.5)*1.3 + 0.5,0,1)\n",
    "    return np.clip(tampered,0,1)\n",
    "\n",
    "def create_dataset(system, n_samples=300):\n",
    "    X, y = [], []\n",
    "    for _ in range(n_samples):\n",
    "        host = generate_synthetic_image()\n",
    "        wm = system.text_to_watermark(\"HELLO\", (32,32))\n",
    "        alpha = system.adaptive_alpha(system.calculate_complexity(host))\n",
    "        watermarked = system.embed_watermark(host, wm, alpha)\n",
    "        # Authentic (label 1)\n",
    "        features_auth = system.extract_features(host, watermarked)\n",
    "        X.append(features_auth); y.append(1)\n",
    "        # Tampered (label 0)\n",
    "        tampered = apply_random_tamper(watermarked)\n",
    "        features_tamp = system.extract_features(host, tampered)\n",
    "        X.append(features_tamp); y.append(0)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  ML Model Training & Evaluation\n",
    "# ============================================================\n",
    "\n",
    "system = SimpleWatermarkSystem()\n",
    "X, y = create_dataset(system, n_samples=400)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=16, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“Š Results and Plots\n",
    "# ============================================================\n",
    "\n",
    "# --- Accuracy and Loss curves ---\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Model Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Model Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Predictions ---\n",
    "y_pred_prob = model.predict(X_val).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Tampered','Authentic'], yticklabels=['Tampered','Authentic'])\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred, target_names=['Tampered','Authentic']))\n",
    "\n",
    "# --- ROC Curve ---\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Final Validation Accuracy: {np.mean(y_pred == y_val)*100:.2f}%\")\n",
    "print(f\"âœ… AUC Score: {roc_auc:.3f}\")\n",
    "\n",
    "# Save model for later\n",
    "model.save(\"authenticity_classifier.h5\")\n",
    "print(\"\\nðŸ’¾ Model saved as authenticity_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bea6c-b295-41fa-a845-be1421e6b2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
